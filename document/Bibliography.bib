<<<<<<< HEAD
@article{hey2020machinelearning,
	author = {Hey, Tony and Butler, Keith and Jackson, Sam and Thiyagalingam, Jeyarajan},
	year = {2020},
	month = {03},
	pages = {20190054},
	title = {Machine learning and big scientific data},
	volume = {378},
	journal = {Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences},
	doi = {10.1098/rsta.2019.0054}
}

@inproceedings{thornton2013auto,
	author = {Thornton, Chris and Hutter, Frank and Hoos, Holger H and Leyton-Brown, Kevin},
	booktitle = {Proceedings of the 19th ACM SIGKDD international conference on Knowledge discovery and data mining},
	pages = {847--855},
	title = {Auto-WEKA: Combined selection and hyperparameter optimization of classification algorithms},
	year = {2013}
=======
@article{biggs1985role,
    author = {Biggs, J. B.},
    title = {The Role of Metalearning in Study Processes},
    journal = {British Journal of Educational Psychology},
    volume = {55},
    number = {3},
    pages = {185-212},
    doi = {https://doi.org/10.1111/j.2044-8279.1985.tb02625.x},
    url = {https://bpspsychub.onlinelibrary.wiley.com/doi/abs/10.1111/j.2044-8279.1985.tb02625.x},
    eprint = {https://bpspsychub.onlinelibrary.wiley.com/doi/pdf/10.1111/j.2044-8279.1985.tb02625.x},
    abstract = {Summary. Effective learning under institutional conditions requires, first, that students are aware of task demands and of their intentions of how, or even whether, to meet those demands, and, second, that they assess realistically, and exert control over, their own cognitive resources. The fulfilment of such conditions involves a sophisticated kind of metacognition, here called metalearning. The present paper describes a series of studies that collectively explicate the development and role of metalearning in the learning and study processes of secondary and tertiary students. Ability patterns, locus of control, variety and quality of certain non-school experiences, and extent and kind of motivation all seem to be involved in the development of metalearning capability. A model of student learning is then described, in which personal and situational factors are linked to performance by three main approaches to learning: deep, achieving, and surface. These approaches involve varying degrees of metalearning and lead to qualitatively different learning outcomes. An intervention study on improving student learning is described that tests important aspects of the model, and further implications for teaching and research are suggested.},
    year = {1985}
}

@article{hospedales2021metalearning,
	author = {Hospedales, Timothy and Antoniou, Antreas and Micaelli, Paul and Storkey, Amos},
	doi = {10.1109/TPAMI.2021.3079209},
	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	month = {05},
	pages = {1-1},
	title = {Meta-Learning in Neural Networks: A Survey},
	volume = {PP},
	year = {2021},
	Bdsk-Url-1 = {https://doi.org/10.1109/TPAMI.2021.3079209}
}

@article{lemke2013metalearning,
	author = {Lemke, Christiane and Budka, Marcin and Gabrys, Bogdan},
	doi = {10.1007/s10462-013-9406-y},
	journal = {Artificial Intelligence Review},
	month = {06},
	title = {Metalearning: a survey of trends and technologies},
	volume = {DOI: 10.1007/s10462-013-9406-y},
	year = {2013},
	Bdsk-Url-1 = {https://doi.org/10.1007/s10462-013-9406-y}
}

@inbook{bradzil2017metalearning,
	author = {Brazdil, Pavel and Vilalta, Ricardo and Giraud-Carrier, Christophe and Soares, Carlos},
	year = {2017},
	month = {01},
	pages = {},
	title = {Metalearning},
	doi = {10.1007/978-1-4899-7687-1_543}
}

@article{peng2020comprehensive,
  author    = {Huimin Peng},
  title     = {A Comprehensive Overview and Survey of Recent Advances in Meta-Learning},
  journal   = {CoRR},
  volume    = {abs/2004.11149},
  year      = {2020},
  url       = {https://arxiv.org/abs/2004.11149},
  eprinttype = {arXiv},
  eprint    = {2004.11149},
  timestamp = {Sat, 23 Jan 2021 01:11:18 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2004-11149.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@book{hutter2019autmlbook,
	author = {Hutter, Frank and Kotthoff, Lars and Vanschoren, Joaquin},
	title = {Automated Machine Learning: Methods, Systems, Challenges},
	year = {2019},
	isbn = {3030053172},
	publisher = {Springer Publishing Company, Incorporated},
	edition = {1st},
	abstract = {This open access book presents the first comprehensive overview of general methods
	in Automated Machine Learning (AutoML), collects descriptions of existing systems
	based on these methods, and discusses the first series of international challenges
	of AutoML systems. The recent success of commercial ML applications and the rapid
	growth of the field has created a high demand for off-the-shelf ML methods that can
	be used easily and without expert knowledge. However, many of the recent machine learning
	successes crucially rely on human experts, who manually select appropriate ML architectures
	(deep learning architectures or more traditional ML workflows) and their hyperparameters.
	To overcome this problem, the field of AutoML targets a progressive automation of
	machine learning, based on principles from optimization and machine learning itself.
	This book serves as a point of entry into this quickly-developing field for researchers
	and advanced students alike, as well as providing a reference for practitioners aiming
	to use AutoML in their work.}
>>>>>>> background
}

@article{he2021automl,
	title={AutoML: A survey of the state-of-the-art},
	volume={212},
	ISSN={0950-7051},
	url={http://dx.doi.org/10.1016/j.knosys.2020.106622},
	DOI={10.1016/j.knosys.2020.106622},
	journal={Knowledge-Based Systems},
	publisher={Elsevier BV},
	author={He, Xin and Zhao, Kaiyong and Chu, Xiaowen},
	year={2021},
	month={Jan},
	pages={106622}
}

<<<<<<< HEAD
@inproceedings{dyrmishi2019decision,
	author = {Dyrmishi, Salijona and El Shawi, Radwa and Sakr, Sherif},
	year = {2019},
	month = {11},
	pages = {97-106},
	title = {A Decision Support Framework for AutoML Systems: A Meta-Learning Approach},
	doi = {10.1109/ICDMW.2019.00025}
}

@inproceedings{autogoal,
	title = "Automatic Discovery of Heterogeneous Machine Learning Pipelines: An Application to Natural Language Processing",
	author = "Estevez-Velarde, Suilan  and
	Guti{\'e}rrez, Yoan  and
	Montoyo, Andres  and
	Almeida Cruz, Yudivi{\'a}n",
	booktitle = "Proceedings of the 28th International Conference on Computational Linguistics",
	month = dec,
	year = "2020",
	address = "Barcelona, Spain (Online)",
	publisher = "International Committee on Computational Linguistics",
	url = "https://aclanthology.org/2020.coling-main.317",
	doi = "10.18653/v1/2020.coling-main.317",
	pages = "3558--3568",
	abstract = "This paper presents AutoGOAL, a system for automatic machine learning (AutoML) that uses heterogeneous techniques. In contrast with existing AutoML approaches, our contribution can automatically build machine learning pipelines that combine techniques and algorithms from different frameworks, including shallow classifiers, natural language processing tools, and neural networks. We define the heterogeneous AutoML optimization problem as the search for the best sequence of algorithms that transforms specific input data into the desired output. This provides a novel theoretical and practical approach to AutoML. Our proposal is experimentally evaluated in diverse machine learning problems and compared with alternative approaches, showing that it is competitive with other AutoML alternatives in standard benchmarks. Furthermore, it can be applied to novel scenarios, such as several NLP tasks, where existing alternatives cannot be directly deployed. The system is freely available and includes in-built compatibility with a large number of popular machine learning frameworks, which makes our approach useful for solving practical problems with relative ease and effort.",
}

@inbook{crisan2021fits,
    author = {Crisan, Anamaria and Fiore-Gartland, Brittany},
    title = {Fits and Starts: Enterprise Use of AutoML and the Role of Humans in the Loop},
    year = {2021},
    isbn = {9781450380966},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    url = {https://doi.org/10.1145/3411764.3445775},
    abstract = { AutoML systems can speed up routine data science work and make machine learning available
    to those without expertise in statistics and computer science. These systems have
    gained traction in enterprise settings where pools of skilled data workers are limited.
    In this study, we conduct interviews with 29 individuals from organizations of different
    sizes to characterize how they currently use, or intend to use, AutoML systems in
    their data science work. Our investigation also captures how data visualization is
    used in conjunction with AutoML systems. Our findings identify three usage scenarios
    for AutoML that resulted in a framework summarizing the level of automation desired
    by data workers with different levels of expertise. We surfaced the tension between
    speed and human oversight and found that data visualization can do a poor job balancing
    the two. Our findings have implications for the design and implementation of human-in-the-loop
    visual analytics approaches.},
    booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
    articleno = {601},
    numpages = {15}
=======
@article{zoph2017learning,
	author    = {Barret Zoph and
	Vijay Vasudevan and
	Jonathon Shlens and
	Quoc V. Le},
	title     = {Learning Transferable Architectures for Scalable Image Recognition},
	journal   = {CoRR},
	volume    = {abs/1707.07012},
	year      = {2017},
	url       = {http://arxiv.org/abs/1707.07012},
	eprinttype = {arXiv},
	eprint    = {1707.07012},
	timestamp = {Mon, 13 Aug 2018 16:48:00 +0200},
	biburl    = {https://dblp.org/rec/journals/corr/ZophVSL17.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{witsuba2019nas,
	author    = {Martin Wistuba and
	Ambrish Rawat and
	Tejaswini Pedapati},
	title     = {A Survey on Neural Architecture Search},
	journal   = {CoRR},
	volume    = {abs/1905.01392},
	year      = {2019},
	url       = {http://arxiv.org/abs/1905.01392},
	eprinttype = {arXiv},
	eprint    = {1905.01392},
	timestamp = {Mon, 27 May 2019 13:15:00 +0200},
	biburl    = {https://dblp.org/rec/journals/corr/abs-1905-01392.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}

@misc{bischl2021hyperparameter,
	archiveprefix = {arXiv},
	author = {Bernd Bischl and Martin Binder and Michel Lang and Tobias Pielok and Jakob Richter and Stefan Coors and Janek Thomas and Theresa Ullmann and Marc Becker and Anne-Laure Boulesteix and Difan Deng and Marius Lindauer},
	eprint = {2107.05847},
	primaryclass = {stat.ML},
	title = {Hyperparameter Optimization: Foundations, Algorithms, Best Practices and Open Challenges},
	year = {2021}
}

@inproceedings{fuerer2015efficient,
	author = {Feurer, Matthias and Klein, Aaron and Eggensperger, Katharina and Springenberg, Jost and Blum, Manuel and Hutter, Frank},
	booktitle = {Advances in Neural Information Processing Systems},
	editor = {C. Cortes and N. Lawrence and D. Lee and M. Sugiyama and R. Garnett},
	publisher = {Curran Associates, Inc.},
	title = {Efficient and Robust Automated Machine Learning},
	url = {https://proceedings.neurips.cc/paper/2015/file/11d0e6287202fced83f79975ec59a3a6-Paper.pdf},
	volume = {28},
	year = {2015},
	Bdsk-Url-1 = {https://proceedings.neurips.cc/paper/2015/file/11d0e6287202fced83f79975ec59a3a6-Paper.pdf}
}

@article{estevez2021general,
  title={General-purpose hierarchical optimisation of machine learning pipelines with grammatical evolution},
  author={Est{\'e}vez-Velarde, Suilan and Guti{\'e}rrez, Yoan and Almeida-Cruz, Yudivi{\'a}n and Montoyo, Andr{\'e}s},
  journal={Information Sciences},
  volume={543},
  pages={58--71},
  year={2021},
  publisher={Elsevier}
>>>>>>> background
}

@article{paszke2019pytorch,
  author    = {Adam Paszke and
               Sam Gross and
               Francisco Massa and
               Adam Lerer and
               James Bradbury and
               Gregory Chanan and
               Trevor Killeen and
               Zeming Lin and
               Natalia Gimelshein and
               Luca Antiga and
               Alban Desmaison and
               Andreas K{\"{o}}pf and
               Edward Yang and
               Zach DeVito and
               Martin Raison and
               Alykhan Tejani and
               Sasank Chilamkurthy and
               Benoit Steiner and
               Lu Fang and
               Junjie Bai and
               Soumith Chintala},
  title     = {PyTorch: An Imperative Style, High-Performance Deep Learning Library},
  journal   = {CoRR},
  volume    = {abs/1912.01703},
  year      = {2019},
  url       = {http://arxiv.org/abs/1912.01703},
  eprinttype = {arXiv},
  eprint    = {1912.01703},
  timestamp = {Thu, 02 Jan 2020 18:08:18 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1912-01703.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

<<<<<<< HEAD



=======
@misc{web-mlpipe, 
 	title={What is a machine learning pipeline?}, url={https://valohai.com/machine-learning-pipeline/}, 
 	journal={What is a Machine Learning Pipeline?}
}

@techreport{wolpert1995no,
	author = {Wolpert, David H and Macready, William G and others},
	institution = {Technical Report SFI-TR-95-02-010, Santa Fe Institute},
	title = {No free lunch theorems for search},
	year = {1995}
}

@inproceedings{thornton2013auto,
	author = {Thornton, Chris and Hutter, Frank and Hoos, Holger H and Leyton-Brown, Kevin},
	booktitle = {Proceedings of the 19th ACM SIGKDD international conference on Knowledge discovery and data mining},
	pages = {847--855},
	title = {Auto-WEKA: Combined selection and hyperparameter optimization of classification algorithms},
	year = {2013}
}

@inbook{fuerer2019hyperparameter,
	author = {Feurer, Matthias and Hutter, Frank},
	year = {2019},
	month = {05},
	pages = {3-33},
	title = {Hyperparameter Optimization},
	isbn = {978-3-030-05317-8},
	doi = {10.1007/978-3-030-05318-5_1}
}

@inproceedings{li2021automl,
  title={Automl: From methodology to application},
  author={Li, Yaliang and Wang, Zhen and Xie, Yuexiang and Ding, Bolin and Zeng, Kai and Zhang, Ce},
  booktitle={Proceedings of the 30th ACM International Conference on Information \& Knowledge Management},
  pages={4853--4856},
  year={2021}
}

@misc{vanschoren2018metalearning,
	archiveprefix = {arXiv},
	author = {Joaquin Vanschoren},
	eprint = {1810.03548},
	primaryclass = {cs.LG},
	title = {Meta-Learning: A Survey},
	year = {2018}
}

@article{Rivolli2018TowardsRE,
	author = {Adriano Rivolli and L. P. F. Garcia and Carlos Soares and J. Vanschoren and A. Carvalho},
	journal = {ArXiv},
	title = {Towards Reproducible Empirical Research in Meta-Learning},
	volume = {abs/1808.10406},
	year = {2018}
}

@book{bradzil2009metalearning,
	author = {Brazdil, Pavel and Giraud-Carrier, Christophe and Soares, Carlos and Vilalta, Ricardo},
	doi = {10.1007/978-3-540-73263-1},
	isbn = {978-3-540-73262-4},
	journal = {Metalearning: Applications to Data Mining, Cognitive Technologies. ISBN 978-3-540-73262-4. Springer Berlin Heidelberg, 2009},
	month = {01},
	title = {Metalearning - Applications to Data Mining.},
	year = {2009},
	Bdsk-Url-1 = {https://doi.org/10.1007/978-3-540-73263-1}
}

@article{estevanellhacia,
  title={Hacia la democratizaci{\'o}n del aprendizaje de m{\'a}quinas usando AutoGOAL Towards the Democratization of Machine Learning using AutoGOAL},
  author={Estevanell-Valladares, Ernesto Luis and Estevez-Velarde, Suilan and Piad-Morffis, Alejandro and Guti{\'e}rrez, Yoan and Montoyo, Andr{\'e}s}
}
>>>>>>> background
